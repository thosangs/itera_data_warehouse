services:
  zookeeper:
    image: quay.io/debezium/zookeeper:3.1
    container_name: zookeeper
    ports: ["2181:2181"]

  kafka:
    image: quay.io/debezium/kafka:3.1
    container_name: kafka
    ports: ["9092:9092", "29092:29092"]
    depends_on: [zookeeper]
    environment:
      ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,EXTERNAL://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1

  connect:
    image: quay.io/debezium/connect:3.1
    container_name: connect
    depends_on: [kafka, postgres]
    ports: ["8083:8083"]
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: connect_configs
      OFFSET_STORAGE_TOPIC: connect_offsets
      STATUS_STORAGE_TOPIC: connect_statuses
      CONFIG_STORAGE_REPLICATION_FACTOR: 1
      OFFSET_STORAGE_REPLICATION_FACTOR: 1
      STATUS_STORAGE_REPLICATION_FACTOR: 1
      KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      VALUE_CONVERTER_SCHEMAS_ENABLE: "false"

  postgres:
    image: debezium/postgres:15
    container_name: postgres
    ports: ["5432:5432"]
    command:
      [
        "postgres",
        "-c",
        "wal_level=logical",
        "-c",
        "max_wal_senders=10",
        "-c",
        "max_replication_slots=10",
      ]
    environment:
      POSTGRES_USER: dbz
      POSTGRES_PASSWORD: dbz
      POSTGRES_DB: ${DB_NAME}
    volumes:
      - ../../../:/opt/workspace:ro

  airflow:
    platform: linux/amd64
    build:
      context: ..
      dockerfile: docker/dockerfile.airflow
    container_name: ${AIRFLOW_CONTAINER_NAME}
    hostname: ${AIRFLOW_HOST_NAME}
    entrypoint:
      - /bin/bash
      - /scripts/airflow_entrypoint.sh
    environment:
      POSTGRES_USER: dbz
      POSTGRES_PASSWORD: dbz
      POSTGRES_DB: ${DB_NAME}
    restart: always
    volumes:
      - ../dags:/opt/airflow/dags
      - ../scripts:/scripts
      - ../../../:/opt/workspace
    ports:
      - ${AIRFLOW_WEBSERVER_PORT}:8080

  sqlpad:
    image: sqlpad/sqlpad:7.5.7
    container_name: sqlpad
    depends_on:
      postgres:
        condition: service_started
    ports:
      - "3000:3000"
    environment:
      - SQLPAD_ADMIN=${SQLPAD_ADMIN}
      - SQLPAD_ADMIN_PASSWORD=${SQLPAD_ADMIN_PASSWORD}
      - SQLPAD_APP_LOG_LEVEL=info
      - SQLPAD_WEB_LOG_LEVEL=warn
      - SQLPAD_CONNECTIONS__pg__name=${DB_NAME}
      - SQLPAD_CONNECTIONS__pg__driver=postgres
      - SQLPAD_CONNECTIONS__pg__host=postgres
      - SQLPAD_CONNECTIONS__pg__port=5432
      - SQLPAD_CONNECTIONS__pg__database=${DB_NAME}
      - SQLPAD_CONNECTIONS__pg__username=dbz
      - SQLPAD_CONNECTIONS__pg__password=dbz
    restart: unless-stopped
